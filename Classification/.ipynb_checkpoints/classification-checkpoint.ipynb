{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "least-graham",
   "metadata": {},
   "source": [
    "# Classification in PySpark's MLlib\n",
    "\n",
    "PySpark offers a good variety of algorithms that can be applied to classification machine learning problems. However, because PySpark operates on distributed dataframes, we cannot use popular Python libraries like scikit learn for our machine learning applications. Which means we need to use PySpark's MLlib packages for these tasks. Luckily, MLlib offers a pretty good variety of algorithms! In this notebook we will go over how to prep our data and train and test the classification algorithms PySpark offers. \n",
    "\n",
    "## Algorithms Available\n",
    "\n",
    "PySpark offers the following algorithms for classification. \n",
    "\n",
    "1. Logistic Regression \n",
    "2. Naive Bayes\n",
    "3. One Vs Rest\n",
    "4. Linear Support Vector Machine (SVC)\n",
    "5. Random Forest Classifier\n",
    "6. GBT Classifier\n",
    "7. Decision Tree Classifier\n",
    "8. Multilayer Perceptron Classifier (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-storm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-2NP7FHU.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ff6e979340>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing pysark and creating a session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('classification').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-vanilla",
   "metadata": {},
   "source": [
    "### Data Set Name: Autistic Spectrum Disorder Screening Data for Adult\n",
    "Autistic Spectrum Disorder (ASD) is a neurodevelopment condition associated with significant healthcare costs, and early diagnosis can significantly reduce these. Unfortunately, waiting times for an ASD diagnosis are lengthy and procedures are not cost effective. The economic impact of autism and the increase in the number of ASD cases across the world reveals an urgent need for the development of easily implemented and effective screening methods. Therefore, a time-efficient and accessible ASD screening is imminent to help health professionals and inform individuals whether they should pursue formal clinical diagnosis. The rapid growth in the number of ASD cases worldwide necessitates datasets related to behaviour traits. However, such datasets are rare making it difficult to perform thorough analyses to improve the efficiency, sensitivity, specificity and predictive accuracy of the ASD screening process. Presently, very limited autism datasets associated with clinical or screening are available and most of them are genetic in nature. Hence, we propose a new dataset related to autism screening of adults that contained 20 features to be utilised for further analysis especially in determining influential autistic traits and improving the classification of ASD cases. In this dataset, we record ten behavioural features (AQ-10-Adult) plus ten individuals characteristics that have proved to be effective in detecting the ASD cases from controls in behaviour science.\n",
    "\n",
    "### Source: \n",
    "https://www.kaggle.com/faizunnabi/autism-screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applied-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"datasets-mlib/\"\n",
    "df = spark.read.csv(path+'Toddler Autism dataset July 2018.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rough-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>m</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "5        6   1   1   0   0   1   1   1   1   1    1        21               8   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "5   m           black       no                  no          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  \n",
       "5               Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the dataset\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hired-toolbox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-queue",
   "metadata": {},
   "source": [
    "In the dataset,\n",
    "- Inependent variables (features): Case_No - Who completed the test\n",
    "- Dependent variable: Class/ASD Traits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blocked-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Class/ASD Traits |count|\n",
      "+-----------------+-----+\n",
      "|               No|  326|\n",
      "|              Yes|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of classes in the dpenedent variable\n",
    "df.groupBy(\"Class/ASD Traits \").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-force",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loose-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = df.columns # Collect the column names as a list\n",
    "input_columns = input_columns[1:-1] # keep only relevant columns: from column 1 to \n",
    "\n",
    "dependent_var = 'Class/ASD Traits '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emotional-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the label (class variable) to string type to prep for reindexing\n",
    "# Pyspark expects a zero indexed integer for the label column\n",
    "# Just in case our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "indexed = indexer.fit(renamed).transform(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tracked-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string type data in the input column list to numeric, otherwise the Algorithm will not be able to process it\n",
    "# Also we will use these lists later on\n",
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "for column in input_columns:\n",
    "    # First identify the string vars in your input column list\n",
    "    if str(indexed.schema[column].dataType) == 'StringType':\n",
    "        # Setting up the String Indexer function\n",
    "        indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
    "        # Then call on the indexer created here\n",
    "        indexed = indexer.fit(indexed).transform(indexed)\n",
    "        # Rename the column to a new name so you can disinguish it from the original\n",
    "        new_col_name = column+\"_num\"\n",
    "        # Adding the new column name to the string inputs list\n",
    "        string_inputs.append(new_col_name)\n",
    "    else:\n",
    "        # If no change was needed, take no action \n",
    "        # And add the numeric var to the num list\n",
    "        numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
