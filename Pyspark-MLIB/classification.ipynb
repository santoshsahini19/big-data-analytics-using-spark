{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nearby-linux",
   "metadata": {},
   "source": [
    "# Classification in PySpark's MLlib\n",
    "\n",
    "PySpark offers a good variety of algorithms that can be applied to classification machine learning problems. However, because PySpark operates on distributed dataframes, we cannot use popular Python libraries like scikit learn for our machine learning applications. Which means we need to use PySpark's MLlib packages for these tasks. Luckily, MLlib offers a pretty good variety of algorithms! In this notebook we will go over how to prep our data and train and test the classification algorithms PySpark offers. \n",
    "\n",
    "## Algorithms Available\n",
    "\n",
    "PySpark offers the following algorithms for classification. \n",
    "\n",
    "1. Logistic Regression \n",
    "2. Naive Bayes\n",
    "3. One Vs Rest\n",
    "4. Linear Support Vector Machine (SVC)\n",
    "5. Random Forest Classifier\n",
    "6. GBT Classifier\n",
    "7. Decision Tree Classifier\n",
    "8. Multilayer Perceptron Classifier (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "important-address",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-2NP7FHU.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classification1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2b9963aab80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing pysark and creating a session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('classification1').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conventional-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-clinic",
   "metadata": {},
   "source": [
    "### Data Set Name: Autistic Spectrum Disorder Screening Data for Adult\n",
    "Autistic Spectrum Disorder (ASD) is a neurodevelopment condition associated with significant healthcare costs, and early diagnosis can significantly reduce these. Unfortunately, waiting times for an ASD diagnosis are lengthy and procedures are not cost effective. The economic impact of autism and the increase in the number of ASD cases across the world reveals an urgent need for the development of easily implemented and effective screening methods. Therefore, a time-efficient and accessible ASD screening is imminent to help health professionals and inform individuals whether they should pursue formal clinical diagnosis. The rapid growth in the number of ASD cases worldwide necessitates datasets related to behaviour traits. However, such datasets are rare making it difficult to perform thorough analyses to improve the efficiency, sensitivity, specificity and predictive accuracy of the ASD screening process. Presently, very limited autism datasets associated with clinical or screening are available and most of them are genetic in nature. Hence, we propose a new dataset related to autism screening of adults that contained 20 features to be utilised for further analysis especially in determining influential autistic traits and improving the classification of ASD cases. In this dataset, we record ten behavioural features (AQ-10-Adult) plus ten individuals characteristics that have proved to be effective in detecting the ASD cases from controls in behaviour science.\n",
    "\n",
    "### Source: \n",
    "https://www.kaggle.com/faizunnabi/autism-screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minus-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"datasets-mlib/\"\n",
    "df = spark.read.csv(path+'Toddler Autism dataset July 2018.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handled-brunei",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>m</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "5        6   1   1   0   0   1   1   1   1   1    1        21               8   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "5   m           black       no                  no          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  \n",
       "5               Yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the dataset\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demonstrated-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-conversation",
   "metadata": {},
   "source": [
    "In the dataset,\n",
    "- Inependent variables (features): Case_No - Who completed the test\n",
    "- Dependent variable: Class/ASD Traits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elect-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Class/ASD Traits |count|\n",
      "+-----------------+-----+\n",
      "|               No|  326|\n",
      "|              Yes|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of classes in the dpenedent variable\n",
    "df.groupBy(\"Class/ASD Traits \").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-location",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-prefix",
   "metadata": {},
   "source": [
    "MLib requires all the data to be vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "studied-inside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex',\n",
       " 'Ethnicity',\n",
       " 'Jaundice',\n",
       " 'Family_mem_with_ASD',\n",
       " 'Who completed the test']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separating dependent and independent variables\n",
    "input_columns = df.columns # Collect the column names as a list\n",
    "input_columns = input_columns[1:-1] # keep only relevant columns: from column 1 to \n",
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complex-poverty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class/ASD Traits '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_var = 'Class/ASD Traits '\n",
    "dependent_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "academic-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convwrting the dependent variables columsn from yes, n to 0 and 1\n",
    "renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "handed-wings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0  ...        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0  ...        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0  ...        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1  ...        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1  ...        20               9   \n",
       "\n",
       "   Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0    f  middle eastern      yes                  no          family member   \n",
       "1    m  White European      yes                  no          family member   \n",
       "2    m  middle eastern      yes                  no          family member   \n",
       "3    m        Hispanic       no                  no          family member   \n",
       "4    f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits  label_str label  \n",
       "0                No        No   1.0  \n",
       "1               Yes       Yes   0.0  \n",
       "2               Yes       Yes   0.0  \n",
       "3               Yes       Yes   0.0  \n",
       "4               Yes       Yes   0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed = indexer.fit(renamed).transform(renamed)\n",
    "indexed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "legitimate-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the string type data in the input column list to numeric, otherwise pyspark cannot process it\n",
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "for column in input_columns:\n",
    "    #Identifying string type variables\n",
    "    if str(indexed.schema[column].dataType) == 'StringType':\n",
    "        #Setting up string indexer function \n",
    "        indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\")\n",
    "        #Calling the indexer function\n",
    "        indexed = indexer.fit(indexed).transform(indexed)\n",
    "        #Collecting the new column names\n",
    "        new_col_name = column+\"_num\"\n",
    "        #Appending the column name to string input list\n",
    "        string_inputs.append(new_col_name)\n",
    "    else:\n",
    "        numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wrapped-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "      <th>Sex_num</th>\n",
       "      <th>Ethnicity_num</th>\n",
       "      <th>Jaundice_num</th>\n",
       "      <th>Family_mem_with_ASD_num</th>\n",
       "      <th>Who completed the test_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  Family_mem_with_ASD  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0  ...                   no   \n",
       "1        2   1   1   0   0   0   1   1   0   0  ...                   no   \n",
       "2        3   1   0   0   0   0   0   1   1   0  ...                   no   \n",
       "3        4   1   1   1   1   1   1   1   1   1  ...                   no   \n",
       "4        5   1   1   0   1   1   1   1   1   1  ...                  yes   \n",
       "\n",
       "   Who completed the test  Class/ASD Traits  label_str label Sex_num  \\\n",
       "0           family member                 No        No   1.0     1.0   \n",
       "1           family member                Yes       Yes   0.0     0.0   \n",
       "2           family member                Yes       Yes   0.0     0.0   \n",
       "3           family member                Yes       Yes   0.0     0.0   \n",
       "4           family member                Yes       Yes   0.0     1.0   \n",
       "\n",
       "  Ethnicity_num Jaundice_num Family_mem_with_ASD_num  \\\n",
       "0           2.0          1.0                     0.0   \n",
       "1           0.0          1.0                     0.0   \n",
       "2           2.0          1.0                     0.0   \n",
       "3           5.0          0.0                     0.0   \n",
       "4           0.0          0.0                     1.0   \n",
       "\n",
       "  Who completed the test_num  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-volume",
   "metadata": {},
   "source": [
    "#### Treating for skewness and outliers\n",
    "\n",
    "Skewness measures how much a distribution of values deviates from symmetry around the mean. A value of zero means the distribution is symmetric, while a positive skewness indicates a greater number of smaller values, and a negative value indicates a greater number of larger values. \n",
    "\n",
    "As a general rule of thumb: \n",
    "\n",
    " - If skewness is **less than -1 or greater than 1**, the distribution is highly skewed. \n",
    " - If skewness is **between -1 and -0.5 or between 0.5 and 1**, the distribution is moderately skewed. \n",
    " - If skewness is **between -0.5 and 0.5**, the distribution is approximately symmetric.\n",
    " \n",
    "A common recommendation for treating skewness is either a log transformation for positive skewed data or an exponential transformation for negatively skewed data.\n",
    "\n",
    "\n",
    "**Outliers** <br>\n",
    "One common way to correct outliers is by flooring and capping which means editing any value that is above or below a certain threshold (99th percentile or 1st percentile) back to the highest/lowest value in that percentile. For example, if the 99th percentile is 96 and there is a value of 1,000, you would change that value to 96. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "altered-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty dictionary d\n",
    "d = {}\n",
    "# Creating a dictionary of quantiles from numeric cols, Doing the top and bottom 1% but it can be adjusted if needed\n",
    "for col in numeric_inputs: \n",
    "    d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) #if you want to make it go faster increase the last number\n",
    "\n",
    "#Now check for skewness for all numeric cols\n",
    "for col in numeric_inputs:\n",
    "    skew = indexed.agg(skewness(indexed[col])).collect() #check for skewness\n",
    "    skew = skew[0][0]\n",
    "    # If skewness is found,\n",
    "    # This function will make the appropriate corrections\n",
    "    if skew > 1: # If right skew, floor, cap and log(x+1)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        log(when(df[col] < d[col][0],d[col][0])\\\n",
    "        .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "        .otherwise(indexed[col] ) +1).alias(col))\n",
    "        print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\n",
    "    elif skew < -1: # If left skew floor, cap and exp(x)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        exp(when(df[col] < d[col][0],d[col][0])\\\n",
    "        .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "        .otherwise(indexed[col] )).alias(col))\n",
    "        print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-julian",
   "metadata": {},
   "source": [
    "As I didn't get any print statements executed above, I can conclude the data is not treated for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "electronic-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values were found in your dataframe.\n"
     ]
    }
   ],
   "source": [
    "#Checking for negative values in the dataframe \n",
    "#Producign a warning if there are negative values in the dataframe that Naive Bayes cannot be used\n",
    "#Note: Checking only the numeric input values since anything that is indexed won't have negative values\n",
    "\n",
    "# Calculating the mins for all columns in the df\n",
    "minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) \n",
    "# Creating an array for all mins and select only the input cols\n",
    "min_array = minimums.select(array(numeric_inputs).alias(\"mins\")) \n",
    "# Collecting global min as Python object\n",
    "df_minimum = min_array.select(array_min(min_array.mins)).collect() \n",
    "# Slicing to get the number itself\n",
    "df_minimum = df_minimum[0][0] \n",
    "\n",
    "# If there are ANY negative vals found in the df, print a warning message\n",
    "if df_minimum < 0:\n",
    "    print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\n",
    "else:\n",
    "    print(\"No negative values were found in your dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "south-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating final features list\n",
    "features_list = numeric_inputs + string_inputs\n",
    "# Creating vector assembler object\n",
    "assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n",
    "# And calling on the vector assembler to transform your dataframe\n",
    "output = assembler.transform(indexed).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "closing-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(17,[6,7,9,10,11,...|  1.0|\n",
      "|(17,[0,1,5,6,10,1...|  0.0|\n",
      "|(17,[0,6,7,9,10,1...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,0.0,0.0,...|  0.0|\n",
      "|(17,[0,3,4,5,8,10...|  0.0|\n",
      "|(17,[1,4,6,7,8,9,...|  0.0|\n",
      "|(17,[6,9,10,11,13...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|[1.0,0.0,0.0,1.0,...|  0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,12,13,14]...|  1.0|\n",
      "|[1.0,1.0,1.0,1.0,...|  0.0|\n",
      "|(17,[10,13],[18.0...|  1.0|\n",
      "|(17,[0,1,2,4,6,7,...|  0.0|\n",
      "|(17,[10,13,15],[3...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "|(17,[0,4,9,10,11,...|  1.0|\n",
      "|[1.0,1.0,1.0,0.0,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "controlled-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled to range: [0.000000, 1000.000000]\n"
     ]
    }
   ],
   "source": [
    "# Creating the mix max scaler object (process if there are negative values present)\n",
    "#Udsing range 0 to 1000\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",min=0,max=1000)\n",
    "print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n",
    "# Computing summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scaler.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "norman-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, scaledFeatures: vector]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rescaling each feature to range [min, max].\n",
    "scaled_data = scalerModel.transform(output)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "promotional-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(17,[6,7,9,10,11,...|\n",
      "|  0.0|(17,[0,1,5,6,10,1...|\n",
      "|  0.0|(17,[0,6,7,9,10,1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  0.0|[1000.0,1000.0,0....|\n",
      "|  0.0|[1000.0,1000.0,0....|\n",
      "|  0.0|(17,[0,3,4,5,8,10...|\n",
      "|  0.0|(17,[1,4,6,7,8,9,...|\n",
      "|  1.0|(17,[6,9,10,11,13...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  0.0|[1000.0,0.0,0.0,1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[10,12,13,14]...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[10,13],[250....|\n",
      "|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "|  1.0|(17,[10,13,15],[1...|\n",
      "|  0.0|[1000.0,1000.0,10...|\n",
      "|  1.0|(17,[0,4,9,10,11,...|\n",
      "|  0.0|(17,[0,1,2,4,6,7,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = scaled_data.select('label','scaledFeatures')\n",
    "# Renaming to default value\n",
    "final_data = final_data.withColumnRenamed(\"scaledFeatures\",\"features\")\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-hollow",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "union-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test\n",
    "train, test = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afraid-talent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dietary-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-plaintiff",
   "metadata": {},
   "source": [
    "##### Reading in dependencies from PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deadly-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "further-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up our evaluation objects\n",
    "binary_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "MC_eval = MulticlassClassificationEvaluator(metricName='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-acceptance",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression\n",
    "The Logistic Regression Algorithm, also known as \"Logit\", is used to estimate (guess) the probability (a number between 0 and 1) of an event occurring having been given some previous data to “learn” from. It works with either binary or multinomial (more than 2 categories) data and uses logistic function (ie. log) to find a model that fits with the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "awful-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiatng logistic regression constructor\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "quality-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitModel = classifier.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "textile-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation method for binary classification problem\n",
    "predictionAndLabels = fitModel.transform(test)\n",
    "auc = binary_eval.evaluate(predictionAndLabels)\n",
    "print(\"AUC:\",auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-apple",
   "metadata": {},
   "source": [
    "#### Cross valdation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "further-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the classifier\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "automatic-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up parameter grid for the cross validator\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10,15,20]).build())\n",
    "\n",
    "#Setting up cross validator\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                         estimatorParamMaps=paramGrid,\n",
    "                         evaluator=MC_eval,\n",
    "                         numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "annoying-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "fitModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "natural-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:[26.84292337550994]\n",
      "CoefficientsDenseMatrix([[-5.68957493e-03, -5.45318699e-03, -5.16569166e-03,\n",
      "              -5.87594904e-03, -5.09657030e-03, -5.92895640e-03,\n",
      "              -6.17518685e-03, -5.54693837e-03, -6.17501559e-03,\n",
      "              -5.79022842e-03, -6.69887614e-04, -1.58644578e-02,\n",
      "               8.22293467e-05, -1.15586711e-03, -7.19309787e-05,\n",
      "               2.25025336e-04, -2.71323550e-03]])\n"
     ]
    }
   ],
   "source": [
    "#Collecting the best model\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept:\" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients\" + str(BestModel.coefficientMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "consecutive-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegressionModel: uid=LogisticRegression_63545fb5557c, numClasses=2, numFeatures=17\n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "#We can extract the best model from this run like below\n",
    "LR_BestModel = BestModel\n",
    "print(\"Best model:\", LR_BestModel)\n",
    "#Generating the prediction\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "#Calculating the accuracy\n",
    "accuracy = (MC_eval.evaluate(predictions))*100\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-julian",
   "metadata": {},
   "source": [
    "#### Classification Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mineral-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the summary\n",
    "trainingSummary = LR_BestModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "english-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|             label|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               751|               751|\n",
      "|   mean|0.3249001331557923|0.3249001331557923|\n",
      "| stddev| 0.468649645271727| 0.468649645271727|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               1.0|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate descibe\n",
    "trainingSummary.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fatal-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective History at each iteration\n",
      "0.6305080142244923\n",
      "0.5213027152588892\n",
      "0.45697304682735296\n",
      "0.28172682941507166\n",
      "0.25450563807118987\n",
      "0.2150518588866581\n",
      "0.19477127698376415\n",
      "0.17340394922408264\n",
      "0.14213392712486164\n",
      "0.08315770329642269\n",
      "0.06440491310915293\n",
      "0.026968891896859117\n",
      "0.018902946707378104\n",
      "0.013639940469738451\n",
      "0.01221273057277904\n",
      "0.00588014351459365\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"Objective History at each iteration\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "popular-rally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "#For multiclass, we can inspect metrics on a per-label basis\n",
    "print(\" \")\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "committed-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Generating confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
